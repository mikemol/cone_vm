name: milestone-tests-and-audit

on:
  push:
    branches:
      - main
      - stage
    paths:
      - ".github/workflows/**"
      - "ci_trigger.txt"
      - "in/**"
      - "tests/**"
      - "scripts/**"
      - "prism_vm.py"
      - "IMPLEMENTATION_PLAN.md"
      - "semantic_audit.md"
      - "audit_in_versions.md"

permissions:
  contents: read

env:
  PYTHON_VERSION: "3.14"

jobs:
  policy-check:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      actions: read
    steps:
      - uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5
      - uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      - name: Install policy check dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install pyyaml
      - name: Diagnose policy token access
        env:
          POLICY_GITHUB_TOKEN: ${{ secrets.POLICY_GITHUB_TOKEN }}
          GITHUB_REPOSITORY: ${{ github.repository }}
        run: |
          set -euo pipefail
          if [ -z "${POLICY_GITHUB_TOKEN:-}" ]; then
            echo "POLICY_GITHUB_TOKEN is empty"
            exit 1
          fi
          token_len=${#POLICY_GITHUB_TOKEN}
          echo "policy-check diagnostics:"
          echo "  token length: ${token_len}"
          case "$POLICY_GITHUB_TOKEN" in
            github_pat_*) echo "  token prefix: github_pat_" ;;
            *) echo "  token prefix: (non github_pat)" ;;
          esac
          python - <<'PY'
          import os
          import hashlib
          token = os.environ["POLICY_GITHUB_TOKEN"]
          has_newline = ("\n" in token) or ("\r" in token)
          print(f"  token contains newline: {'yes' if has_newline else 'no'}")
          fingerprint = hashlib.sha256(token.encode("utf-8")).hexdigest()[:8]
          print(f"  token sha256 prefix: {fingerprint}")
          PY
          auth_header="Authorization: Bearer ${POLICY_GITHUB_TOKEN}"
          accept_header="Accept: application/vnd.github+json"
          base="https://api.github.com/repos/${GITHUB_REPOSITORY}"
          code_user=$(curl -sS -o /dev/null -w "%{http_code}" -H "$accept_header" -H "$auth_header" https://api.github.com/user)
          echo "  GET /user -> ${code_user}"
          code_perms=$(curl -sS -o /dev/null -w "%{http_code}" -H "$accept_header" -H "$auth_header" "${base}/actions/permissions")
          echo "  GET /actions/permissions -> ${code_perms}"
          code_workflow=$(curl -sS -o /dev/null -w "%{http_code}" -H "$accept_header" -H "$auth_header" "${base}/actions/permissions/workflow")
          echo "  GET /actions/permissions/workflow -> ${code_workflow}"
          code_selected=$(curl -sS -o /dev/null -w "%{http_code}" -H "$accept_header" -H "$auth_header" "${base}/actions/permissions/selected-actions")
          echo "  GET /actions/permissions/selected-actions -> ${code_selected}"
      - name: Run policy checks
        env:
          POLICY_GITHUB_TOKEN: ${{ secrets.POLICY_GITHUB_TOKEN }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          python scripts/policy_check.py --workflows --posture

  audit:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5
      - uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      - name: Generate audit
        run: |
          mkdir -p artifacts
          python scripts/audit_in_versions.py --output artifacts/audit_in_versions.md
      - name: Upload audit artifact
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          name: audit
          path: artifacts/audit_in_versions.md

  tests:
    needs: [policy-check, audit]
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        milestone: [m1, m2, m3, m4, m5]
    steps:
      - uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5
      - uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install pytest jax jaxlib
      - name: Run pytest (milestone)
        run: |
          mkdir -p artifacts
          set -euo pipefail
          pytest -c pytest.${{ matrix.milestone }}.ini \
            --junitxml artifacts/pytest-${{ matrix.milestone }}.xml \
            2>&1 | tee artifacts/pytest-${{ matrix.milestone }}.txt
      - name: Run damage metrics fixture (arena)
        if: matrix.milestone == 'm4'
        run: |
          mkdir -p artifacts
          set -euo pipefail
          PRISM_DAMAGE_METRICS=1 PRISM_DAMAGE_TILE_SIZE=2 \
            python prism_vm.py --mode arena --morton --cycles 2 \
            tests/damage_metrics.txt 2>&1 | tee artifacts/damage_metrics.txt
          PRISM_DAMAGE_METRICS=1 PRISM_DAMAGE_TILE_SIZE=32 \
            python prism_vm.py --mode arena --morton --cycles 2 \
            tests/damage_metrics.txt 2>&1 | tee artifacts/damage_metrics_tile32.txt
          PRISM_DAMAGE_METRICS=0 \
            python prism_vm.py --mode arena --morton --cycles 2 \
            tests/damage_metrics_off.txt 2>&1 | tee artifacts/damage_metrics_off.txt
          python scripts/damage_metrics_delta.py \
            --inputs artifacts/damage_metrics.txt artifacts/damage_metrics_tile32.txt \
            --out artifacts/damage_metrics_delta.txt
      - name: Capture host performance baselines
        if: matrix.milestone == 'm4'
        run: |
          mkdir -p artifacts
          python scripts/audit_host_performance.py \
            --engine intrinsic --iterations 5 --warmup 1 \
            --json-out artifacts/host_perf_intrinsic.json
          python scripts/audit_host_performance.py \
            --engine cnf2 --iterations 5 --warmup 1 \
            --json-out artifacts/host_perf_cnf2.json
          python scripts/audit_memory_stability.py \
            --engine intrinsic --iterations 5 --warmup 1 \
            --json-out artifacts/host_memory_intrinsic.json
          python scripts/audit_memory_stability.py \
            --engine cnf2 --iterations 5 --warmup 1 \
            --json-out artifacts/host_memory_cnf2.json
      - name: Upload pytest artifact
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          name: pytest-${{ matrix.milestone }}
          path: artifacts/

  tests-gpu:
    needs: [policy-check, audit]
    if: github.actor == github.repository_owner && needs.policy-check.result == 'success' && needs.audit.result == 'success'
    runs-on: [self-hosted, cassian, gpu, local]
    strategy:
      fail-fast: false
      matrix:
        milestone: [m2]
    steps:
      - uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5
      - name: Ensure mise Python is installed (self-hosted)
        run: |
          if ! command -v mise >/dev/null 2>&1; then
            echo "mise is required on the self-hosted runner" >&2
            exit 1
          fi
          mise install
      - name: Verify python version (self-hosted)
        run: |
          mise exec -- python - <<'PY'
          import os
          import sys
          want = os.environ["PYTHON_VERSION"]
          version = sys.version.split()[0]
          if not version.startswith(want):
              raise SystemExit(f"Expected Python {want}, found {version}")
          print("Python version:", version)
          PY
      - name: Install test dependencies (GPU)
        run: |
          mise exec -- python -m pip install --upgrade pip
          mise exec -- python -m pip install pytest nvidia-ml-py "jax[cuda12]" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html
      - name: Verify GPU backend
        run: |
          mise exec -- python - <<'PY'
          import jax
          gpus = jax.devices("gpu")
          if not gpus:
              raise SystemExit("GPU backend required but not available")
          print("GPU devices:", gpus)
          PY
      - name: Run pytest (milestone, backend matrix)
        run: |
          mkdir -p artifacts
          set -euo pipefail
          mise exec -- python -m pytest -c pytest.${{ matrix.milestone }}.ini \
            --junitxml artifacts/pytest-gpu-${{ matrix.milestone }}.xml \
            2>&1 | tee artifacts/pytest-gpu-${{ matrix.milestone }}.txt
      - name: Run damage metrics fixture (arena, gpu)
        run: |
          mkdir -p artifacts
          set -euo pipefail
          PRISM_DAMAGE_METRICS=1 PRISM_DAMAGE_TILE_SIZE=2 \
            mise exec -- python prism_vm.py --mode arena --morton --cycles 2 \
            tests/damage_metrics.txt 2>&1 | tee artifacts/damage_metrics_gpu.txt
          PRISM_DAMAGE_METRICS=1 PRISM_DAMAGE_TILE_SIZE=32 \
            mise exec -- python prism_vm.py --mode arena --morton --cycles 2 \
            tests/damage_metrics.txt 2>&1 | tee artifacts/damage_metrics_tile32_gpu.txt
          PRISM_DAMAGE_METRICS=0 \
            mise exec -- python prism_vm.py --mode arena --morton --cycles 2 \
            tests/damage_metrics_off.txt 2>&1 | tee artifacts/damage_metrics_off_gpu.txt
          mise exec -- python scripts/damage_metrics_delta.py \
            --inputs artifacts/damage_metrics_gpu.txt artifacts/damage_metrics_tile32_gpu.txt \
            --out artifacts/damage_metrics_delta_gpu.txt
      - name: Upload pytest artifact (gpu)
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          name: pytest-gpu-${{ matrix.milestone }}
          path: artifacts/

  collect-report:
    runs-on: ubuntu-latest
    needs: [policy-check, audit, tests, tests-gpu]
    steps:
      - uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5
      - name: Download all artifacts
        uses: actions/download-artifact@d3f86a106a0bac45b974a628896c90dbdf5c8093
        with:
          path: collected_report/raw
          merge-multiple: true
      - name: Assemble collected report
        run: |
          mkdir -p collected_report
          cp -R collected_report/raw/* collected_report/ || true
          find collected_report -type f | sort > collected_report/contents.txt
          printf "Collected report for milestone audit and tests.\n" > collected_report/README.txt
          printf "Contents:\n" >> collected_report/README.txt
          sed 's|^|  - |' collected_report/contents.txt >> collected_report/README.txt
      - name: Summarize damage metrics telemetry
        run: |
          python3 scripts/collect_damage_metrics.py \
            --base collected_report/raw \
            --out collected_report/damage_metrics_summary.md
      - name: Upload collected report
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          name: collected-report
          path: collected_report/
